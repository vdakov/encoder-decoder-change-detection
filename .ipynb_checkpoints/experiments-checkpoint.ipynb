{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9906210e-fec8-4d95-b132-d94b1f8a223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow (from -r requirements.txt (line 1))\n",
      "  Using cached tensorflow-2.16.1-cp39-cp39-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting matplotlib (from -r requirements.txt (line 2))\n",
      "  Using cached matplotlib-3.8.4-cp39-cp39-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from -r requirements.txt (line 3)) (1.26.3)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 4))\n",
      "  Using cached scikit_learn-1.4.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 5))\n",
      "  Using cached pandas-2.2.2-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting opencv-python (from -r requirements.txt (line 6))\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from -r requirements.txt (line 7)) (2.3.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from -r requirements.txt (line 8)) (0.18.0+cu118)\n",
      "Collecting pyyaml (from -r requirements.txt (line 9))\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting scikit-image (from -r requirements.txt (line 10))\n",
      "  Using cached scikit_image-0.22.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Collecting scipy (from -r requirements.txt (line 11))\n",
      "  Using cached scipy-1.13.0-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Collecting tqdm (from -r requirements.txt (line 12))\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (18.1.1)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (1.63.0)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (0.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (6.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (3.14.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (2021.4.0)\n",
      "Collecting imageio>=2.27 (from scikit-image->-r requirements.txt (line 10))\n",
      "  Using cached imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->-r requirements.txt (line 10))\n",
      "  Using cached tifffile-2024.5.3-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from scikit-image->-r requirements.txt (line 10)) (0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tqdm->-r requirements.txt (line 12)) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 2)) (3.18.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->-r requirements.txt (line 7)) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->-r requirements.txt (line 7)) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 7)) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (0.41.2)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: namex in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (0.0.8)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached optree-0.11.0-cp39-cp39-win_amd64.whl.metadata (46 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (7.1.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vdako\\anaconda3\\envs\\urban-change-detection\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->-r requirements.txt (line 1)) (0.1.2)\n",
      "Using cached tensorflow-2.16.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "Using cached matplotlib-3.8.4-cp39-cp39-win_amd64.whl (7.7 MB)\n",
      "Using cached scikit_learn-1.4.2-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "Using cached opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Using cached scikit_image-0.22.0-cp39-cp39-win_amd64.whl (24.5 MB)\n",
      "Using cached scipy-1.13.0-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "Using cached tifffile-2024.5.3-py3-none-any.whl (225 kB)\n",
      "Using cached keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl (127 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached optree-0.11.0-cp39-cp39-win_amd64.whl (240 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Installing collected packages: tqdm, tifffile, scipy, pyyaml, optree, opencv-python, ml-dtypes, markdown-it-py, imageio, scikit-learn, scikit-image, rich, pandas, matplotlib, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.13.0\n",
      "    Uninstalling tensorboard-2.13.0:\n",
      "      Successfully uninstalled tensorboard-2.13.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.13.1\n",
      "    Uninstalling tensorflow-intel-2.13.1:\n",
      "      Successfully uninstalled tensorflow-intel-2.13.1\n",
      "Successfully installed imageio-2.34.1 keras-3.3.3 markdown-it-py-3.0.0 matplotlib-3.8.4 ml-dtypes-0.3.2 opencv-python-4.9.0.80 optree-0.11.0 pandas-2.2.2 pyyaml-6.0.1 rich-13.7.1 scikit-image-0.22.0 scikit-learn-1.4.2 scipy-1.13.0 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tifffile-2024.5.3 tqdm-4.66.4\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773fc24-7a76-4abc-90ea-357423c76515",
   "metadata": {},
   "source": [
    "#### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38ccb62-9891-43a5-8af3-323bdb7eafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage import io\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm as tqdm\n",
    "import pandas \n",
    "import cv2\n",
    "import os\n",
    "from math import floor, ceil, sqrt, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9dc873",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0cf60ce-47a1-43c3-a478-37ba95274cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_MODIFIER = 10 # Tuning parameter, use 1 if unsure\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "PATCH_SIDE = 96\n",
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f4b8b45-d1fc-4218-afdd-6e906e2d6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LEVIR_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dirname, set_name, patch_side):\n",
    "        self.imgs_1 = {}\n",
    "        self.imgs_2 = {}\n",
    "        self.change_maps = {}\n",
    "        self.stride = 1\n",
    "        \n",
    "\n",
    "        self.n_patches_per_image = {}\n",
    "        self.n_patches = 0\n",
    "        self.patch_coords = []\n",
    "        self.patch_side = patch_side\n",
    "        n_pix = 0\n",
    "        true_pix = 0\n",
    "\n",
    "        for name in os.listdir(os.path.join(dirname,set_name, \"A\")):\n",
    "            img_name = set_name + \"-\" + name\n",
    "            a = reshape_for_torch(cv2.imread(os.path.join(dirname,set_name,\"A\", name)))\n",
    "            b = reshape_for_torch(cv2.imread(os.path.join(dirname,set_name, \"B\", name)))\n",
    "            label = reshape_for_torch(cv2.imread(os.path.join(dirname, set_name, \"label\", name)))\n",
    "\n",
    "            self.imgs_1[img_name] = a\n",
    "            self.imgs_2[img_name] = b\n",
    "            self.change_maps[img_name] = label\n",
    "\n",
    "            s = label.shape\n",
    "            n_pix += np.prod(s)\n",
    "            true_pix += label.sum()\n",
    "            \n",
    "            # calculate the number of patches\n",
    "            s = self.imgs_1[img_name].shape\n",
    "            n1 = ceil((s[1] - self.patch_side + 1) / self.stride)\n",
    "            n2 = ceil((s[2] - self.patch_side + 1) / self.stride)\n",
    "            n_patches_i = n1 * n2\n",
    "            self.n_patches_per_image[img_name] = n_patches_i\n",
    "            self.n_patches += n_patches_i\n",
    "\n",
    "            # generate path coordinates\n",
    "            for i in range(n1):\n",
    "                for j in range(n2):\n",
    "                    # coordinates in (x1, x2, y1, y2)\n",
    "                    current_patch_coords = (img_name, \n",
    "                                    [self.stride*i, self.stride*i + self.patch_side, self.stride*j, self.stride*j + self.patch_side],\n",
    "                                    [self.stride*(i + 1), self.stride*(j + 1)])\n",
    "            self.patch_coords.append(current_patch_coords)\n",
    "            self.weights = [ FP_MODIFIER * 2 * true_pix / n_pix, 2 * (n_pix - true_pix) / n_pix]\n",
    "\n",
    "    def get_img(self, im_name):\n",
    "        return self.imgs_1[im_name], self.imgs_2[im_name], self.change_maps[im_name]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_patches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_patch_coords = self.patch_coords[idx]\n",
    "        im_name = current_patch_coords[0]\n",
    "        limits = current_patch_coords[1]\n",
    "        centre = current_patch_coords[2]\n",
    "        \n",
    "        I1 = self.imgs_1[im_name][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        I2 = self.imgs_2[im_name][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        \n",
    "        label = self.change_maps[im_name][limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        label = torch.from_numpy(1*np.array(label)).float()\n",
    "        \n",
    "        sample = {'I1': I1, 'I2': I2, 'label': label}\n",
    "        \n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5b24222-a11c-4a4f-8b60-92343c263a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([234.0378, -21.4038])\n"
     ]
    }
   ],
   "source": [
    "dirname = \"..\\\\data\\\\LEVIR-CD\"\n",
    "\n",
    "train_dataset = LEVIR_Dataset(dirname, \"train\", PATCH_SIDE)\n",
    "# weights = torch.FloatTensor(train_dataset.weights).cuda()\n",
    "weights = torch.FloatTensor(train_dataset.weights)\n",
    "print(weights)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
    "\n",
    "test_dataset = LEVIR_Dataset(dirname, \"test\", PATCH_SIDE)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
    "\n",
    "val_dataset = LEVIR_Dataset(dirname, \"val\", PATCH_SIDE)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a656e0",
   "metadata": {},
   "source": [
    "#### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1794e31-4389-47a1-a0fc-5863837da7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "import sys\n",
    "sys.path.insert(1, 'siamese_fcn')\n",
    "from unet import Unet\n",
    "from siamunet_conc import SiamUnet_conc\n",
    "from siamunet_diff import SiamUnet_diff\n",
    "from fresunet import FresUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d7bb4a7-5dca-4091-ab36-14c8dcdecb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-RGB | 1-RGBIr | 2-All bands s.t. resulution <= 20m | 3-All bands\n",
    "\n",
    "TYPE = 0\n",
    "\n",
    "\n",
    "if TYPE == 0:\n",
    "#     net, net_name = Unet(2*3, 2), 'FC-EF'\n",
    "#     net, net_name = SiamUnet_conc(3, 2), 'FC-Siam-conc'\n",
    "#     net, net_name = SiamUnet_diff(3, 2), 'FC-Siam-diff'\n",
    "    net, net_name = FresUNet(2*3, 2), 'FresUNet'\n",
    "elif TYPE == 1:\n",
    "#     net, net_name = Unet(2*4, 2), 'FC-EF'\n",
    "#     net, net_name = SiamUnet_conc(4, 2), 'FC-Siam-conc'\n",
    "#     net, net_name = SiamUnet_diff(4, 2), 'FC-Siam-diff'\n",
    "    net, net_name = FresUNet(2*4, 2), 'FresUNet'\n",
    "elif TYPE == 2:\n",
    "#     net, net_name = Unet(2*10, 2), 'FC-EF'\n",
    "#     net, net_name = SiamUnet_conc(10, 2), 'FC-Siam-conc'\n",
    "#     net, net_name = SiamUnet_diff(10, 2), 'FC-Siam-diff'\n",
    "    net, net_name = FresUNet(2*10, 2), 'FresUNet'\n",
    "elif TYPE == 3:\n",
    "#     net, net_name = Unet(2*13, 2), 'FC-EF'\n",
    "#     net, net_name = SiamUnet_conc(13, 2), 'FC-Siam-conc'\n",
    "#     net, net_name = SiamUnet_diff(13, 2), 'FC-Siam-diff'\n",
    "    net, net_name = FresUNet(2*13, 2), 'FresUNet'\n",
    "\n",
    "\n",
    "# net.cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(weight=weights) # to be used with logsoftmax output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f02db1ed-5abf-4f68-8476-3d30918ec307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 1103874\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Number of trainable parameters:', count_parameters(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02438a9d",
   "metadata": {},
   "source": [
    "#### Evaluate Models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e599c2a3-7e91-4ab0-ab22-b28780ce2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('net-best_epoch-1_fm-0.7394933126157746.pth.tar'))\n",
    "\n",
    "def train(n_epochs = N_EPOCHS, save = True):\n",
    "    t = np.linspace(1, n_epochs, n_epochs)\n",
    "    \n",
    "    epoch_train_loss = 0 * t\n",
    "    epoch_train_accuracy = 0 * t\n",
    "    epoch_train_change_accuracy = 0 * t\n",
    "    epoch_train_nochange_accuracy = 0 * t\n",
    "    epoch_train_precision = 0 * t\n",
    "    epoch_train_recall = 0 * t\n",
    "    epoch_train_Fmeasure = 0 * t\n",
    "    epoch_test_loss = 0 * t\n",
    "    epoch_test_accuracy = 0 * t\n",
    "    epoch_test_change_accuracy = 0 * t\n",
    "    epoch_test_nochange_accuracy = 0 * t\n",
    "    epoch_test_precision = 0 * t\n",
    "    epoch_test_recall = 0 * t\n",
    "    epoch_test_Fmeasure = 0 * t\n",
    "    \n",
    "#     mean_acc = 0\n",
    "#     best_mean_acc = 0\n",
    "    fm = 0\n",
    "    best_fm = 0\n",
    "    \n",
    "    lss = 1000\n",
    "    best_lss = 1000\n",
    "    \n",
    "    plt.figure(num=1)\n",
    "    plt.figure(num=2)\n",
    "    plt.figure(num=3)\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), weight_decay=1e-4)\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=0.0005)\n",
    "        \n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95)\n",
    "    \n",
    "    \n",
    "    for epoch_index in tqdm(range(n_epochs)):\n",
    "        net.train()\n",
    "        print('Epoch: ' + str(epoch_index + 1) + ' of ' + str(N_EPOCHS))\n",
    "\n",
    "        tot_count = 0\n",
    "        tot_loss = 0\n",
    "        tot_accurate = 0\n",
    "        class_correct = list(0. for i in range(2))\n",
    "        class_total = list(0. for i in range(2))\n",
    "#         for batch_index, batch in enumerate(tqdm(data_loader)):\n",
    "        for batch in train_loader:\n",
    "            I1 = Variable(batch['I1'].float().cuda())\n",
    "            I2 = Variable(batch['I2'].float().cuda())\n",
    "            label = torch.squeeze(Variable(batch['label'].cuda()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = net(I1, I2)\n",
    "            loss = criterion(output, label.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "        epoch_train_loss[epoch_index], epoch_train_accuracy[epoch_index], cl_acc, pr_rec = test(train_dataset)\n",
    "        epoch_train_nochange_accuracy[epoch_index] = cl_acc[0]\n",
    "        epoch_train_change_accuracy[epoch_index] = cl_acc[1]\n",
    "        epoch_train_precision[epoch_index] = pr_rec[0]\n",
    "        epoch_train_recall[epoch_index] = pr_rec[1]\n",
    "        epoch_train_Fmeasure[epoch_index] = pr_rec[2]\n",
    "        \n",
    "#         epoch_test_loss[epoch_index], epoch_test_accuracy[epoch_index], cl_acc, pr_rec = test(test_dataset)\n",
    "        epoch_test_loss[epoch_index], epoch_test_accuracy[epoch_index], cl_acc, pr_rec = test(test_dataset)\n",
    "        epoch_test_nochange_accuracy[epoch_index] = cl_acc[0]\n",
    "        epoch_test_change_accuracy[epoch_index] = cl_acc[1]\n",
    "        epoch_test_precision[epoch_index] = pr_rec[0]\n",
    "        epoch_test_recall[epoch_index] = pr_rec[1]\n",
    "        epoch_test_Fmeasure[epoch_index] = pr_rec[2]\n",
    "\n",
    "        plt.figure(num=1)\n",
    "        plt.clf()\n",
    "        l1_1, = plt.plot(t[:epoch_index + 1], epoch_train_loss[:epoch_index + 1], label='Train loss')\n",
    "        l1_2, = plt.plot(t[:epoch_index + 1], epoch_test_loss[:epoch_index + 1], label='Test loss')\n",
    "        plt.legend(handles=[l1_1, l1_2])\n",
    "        plt.grid()\n",
    "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
    "        plt.gcf().gca().set_xlim(left = 0)\n",
    "        plt.title('Loss')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.figure(num=2)\n",
    "        plt.clf()\n",
    "        l2_1, = plt.plot(t[:epoch_index + 1], epoch_train_accuracy[:epoch_index + 1], label='Train accuracy')\n",
    "        l2_2, = plt.plot(t[:epoch_index + 1], epoch_test_accuracy[:epoch_index + 1], label='Test accuracy')\n",
    "        plt.legend(handles=[l2_1, l2_2])\n",
    "        plt.grid()\n",
    "        plt.gcf().gca().set_ylim(0, 100)\n",
    "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
    "#         plt.gcf().gca().set_xlim(left = 0)\n",
    "        plt.title('Accuracy')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.figure(num=3)\n",
    "        plt.clf()\n",
    "        l3_1, = plt.plot(t[:epoch_index + 1], epoch_train_nochange_accuracy[:epoch_index + 1], label='Train accuracy: no change')\n",
    "        l3_2, = plt.plot(t[:epoch_index + 1], epoch_train_change_accuracy[:epoch_index + 1], label='Train accuracy: change')\n",
    "        l3_3, = plt.plot(t[:epoch_index + 1], epoch_test_nochange_accuracy[:epoch_index + 1], label='Test accuracy: no change')\n",
    "        l3_4, = plt.plot(t[:epoch_index + 1], epoch_test_change_accuracy[:epoch_index + 1], label='Test accuracy: change')\n",
    "        plt.legend(handles=[l3_1, l3_2, l3_3, l3_4])\n",
    "        plt.grid()\n",
    "        plt.gcf().gca().set_ylim(0, 100)\n",
    "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
    "#         plt.gcf().gca().set_xlim(left = 0)\n",
    "        plt.title('Accuracy per class')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.figure(num=4)\n",
    "        plt.clf()\n",
    "        l4_1, = plt.plot(t[:epoch_index + 1], epoch_train_precision[:epoch_index + 1], label='Train precision')\n",
    "        l4_2, = plt.plot(t[:epoch_index + 1], epoch_train_recall[:epoch_index + 1], label='Train recall')\n",
    "        l4_3, = plt.plot(t[:epoch_index + 1], epoch_train_Fmeasure[:epoch_index + 1], label='Train Dice/F1')\n",
    "        l4_4, = plt.plot(t[:epoch_index + 1], epoch_test_precision[:epoch_index + 1], label='Test precision')\n",
    "        l4_5, = plt.plot(t[:epoch_index + 1], epoch_test_recall[:epoch_index + 1], label='Test recall')\n",
    "        l4_6, = plt.plot(t[:epoch_index + 1], epoch_test_Fmeasure[:epoch_index + 1], label='Test Dice/F1')\n",
    "        plt.legend(handles=[l4_1, l4_2, l4_3, l4_4, l4_5, l4_6])\n",
    "        plt.grid()\n",
    "        plt.gcf().gca().set_ylim(0, 1)\n",
    "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
    "#         plt.gcf().gca().set_xlim(left = 0)\n",
    "        plt.title('Precision, Recall and F-measure')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        \n",
    "        \n",
    "#         mean_acc = (epoch_test_nochange_accuracy[epoch_index] + epoch_test_change_accuracy[epoch_index])/2\n",
    "#         if mean_acc > best_mean_acc:\n",
    "#             best_mean_acc = mean_acc\n",
    "#             save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_acc-' + str(mean_acc) + '.pth.tar'\n",
    "#             torch.save(net.state_dict(), save_str)\n",
    "        \n",
    "        \n",
    "#         fm = pr_rec[2]\n",
    "        fm = epoch_train_Fmeasure[epoch_index]\n",
    "        if fm > best_fm:\n",
    "            best_fm = fm\n",
    "            save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_fm-' + str(fm) + '.pth.tar'\n",
    "            torch.save(net.state_dict(), save_str)\n",
    "        \n",
    "        lss = epoch_train_loss[epoch_index]\n",
    "        if lss < best_lss:\n",
    "            best_lss = lss\n",
    "            save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_loss-' + str(lss) + '.pth.tar'\n",
    "            torch.save(net.state_dict(), save_str)\n",
    "            \n",
    "            \n",
    "#         print('Epoch loss: ' + str(tot_loss/tot_count))\n",
    "        if save:\n",
    "            im_format = 'png'\n",
    "    #         im_format = 'eps'\n",
    "\n",
    "            plt.figure(num=1)\n",
    "            plt.savefig(net_name + '-01-loss.' + im_format)\n",
    "\n",
    "            plt.figure(num=2)\n",
    "            plt.savefig(net_name + '-02-accuracy.' + im_format)\n",
    "\n",
    "            plt.figure(num=3)\n",
    "            plt.savefig(net_name + '-03-accuracy-per-class.' + im_format)\n",
    "\n",
    "            plt.figure(num=4)\n",
    "            plt.savefig(net_name + '-04-prec-rec-fmeas.' + im_format)\n",
    "        \n",
    "    out = {'train_loss': epoch_train_loss[-1],\n",
    "           'train_accuracy': epoch_train_accuracy[-1],\n",
    "           'train_nochange_accuracy': epoch_train_nochange_accuracy[-1],\n",
    "           'train_change_accuracy': epoch_train_change_accuracy[-1],\n",
    "           'test_loss': epoch_test_loss[-1],\n",
    "           'test_accuracy': epoch_test_accuracy[-1],\n",
    "           'test_nochange_accuracy': epoch_test_nochange_accuracy[-1],\n",
    "           'test_change_accuracy': epoch_test_change_accuracy[-1]}\n",
    "    \n",
    "    print('pr_c, rec_c, f_meas, pr_nc, rec_nc')\n",
    "    print(pr_rec)\n",
    "    \n",
    "    return out\n",
    "\n",
    "L = 1024\n",
    "N = 2\n",
    "\n",
    "def test(dset):\n",
    "    net.eval()\n",
    "    tot_loss = 0\n",
    "    tot_count = 0\n",
    "    tot_accurate = 0\n",
    "    \n",
    "    n = 2\n",
    "    class_correct = list(0. for i in range(n))\n",
    "    class_total = list(0. for i in range(n))\n",
    "    class_accuracy = list(0. for i in range(n))\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for img_index in dset.names:\n",
    "        I1_full, I2_full, cm_full = dset.get_img(img_index)\n",
    "        \n",
    "        s = cm_full.shape\n",
    "        \n",
    "\n",
    "        steps0 = np.arange(0,s[0],ceil(s[0]/N))\n",
    "        steps1 = np.arange(0,s[1],ceil(s[1]/N))\n",
    "        for ii in range(N):\n",
    "            for jj in range(N):\n",
    "                xmin = steps0[ii]\n",
    "                if ii == N-1:\n",
    "                    xmax = s[0]\n",
    "                else:\n",
    "                    xmax = steps0[ii+1]\n",
    "                ymin = jj\n",
    "                if jj == N-1:\n",
    "                    ymax = s[1]\n",
    "                else:\n",
    "                    ymax = steps1[jj+1]\n",
    "                I1 = I1_full[:, xmin:xmax, ymin:ymax]\n",
    "                I2 = I2_full[:, xmin:xmax, ymin:ymax]\n",
    "                cm = cm_full[xmin:xmax, ymin:ymax]\n",
    "\n",
    "                I1 = Variable(torch.unsqueeze(I1, 0).float()).cuda()\n",
    "                I2 = Variable(torch.unsqueeze(I2, 0).float()).cuda()\n",
    "                cm = Variable(torch.unsqueeze(torch.from_numpy(1.0*cm),0).float()).cuda()\n",
    "\n",
    "\n",
    "                output = net(I1, I2)\n",
    "                loss = criterion(output, cm.long())\n",
    "        #         print(loss)\n",
    "                tot_loss += loss.data * np.prod(cm.size())\n",
    "                tot_count += np.prod(cm.size())\n",
    "\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "                c = (predicted.int() == cm.data.int())\n",
    "                for i in range(c.size(1)):\n",
    "                    for j in range(c.size(2)):\n",
    "                        l = int(cm.data[0, i, j])\n",
    "                        class_correct[l] += c[0, i, j]\n",
    "                        class_total[l] += 1\n",
    "                        \n",
    "                pr = (predicted.int() > 0).cpu().numpy()\n",
    "                gt = (cm.data.int() > 0).cpu().numpy()\n",
    "                \n",
    "                tp += np.logical_and(pr, gt).sum()\n",
    "                tn += np.logical_and(np.logical_not(pr), np.logical_not(gt)).sum()\n",
    "                fp += np.logical_and(pr, np.logical_not(gt)).sum()\n",
    "                fn += np.logical_and(np.logical_not(pr), gt).sum()\n",
    "        \n",
    "    net_loss = tot_loss/tot_count\n",
    "    net_accuracy = 100 * (tp + tn)/tot_count\n",
    "    \n",
    "    for i in range(n):\n",
    "        class_accuracy[i] = 100 * class_correct[i] / max(class_total[i],0.00001)\n",
    "\n",
    "    prec = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "    f_meas = 2 * prec * rec / (prec + rec)\n",
    "    prec_nc = tn / (tn + fn)\n",
    "    rec_nc = tn / (tn + fp)\n",
    "    \n",
    "    pr_rec = [prec, rec, f_meas, prec_nc, rec_nc]\n",
    "        \n",
    "    return net_loss, net_accuracy, class_accuracy, pr_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b38b9-c975-41d6-b39e-6d6ddf533ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 of 50\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t_start = time.time()\n",
    "out_dic = train()\n",
    "t_end = time.time()\n",
    "print(out_dic)\n",
    "print('Elapsed time:')\n",
    "print(t_end - t_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
