{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9906210e-fec8-4d95-b132-d94b1f8a223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773fc24-7a76-4abc-90ea-357423c76515",
   "metadata": {},
   "source": [
    "#### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38ccb62-9891-43a5-8af3-323bdb7eafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage import io\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm as tqdm\n",
    "import pandas \n",
    "import cv2\n",
    "import os\n",
    "from math import floor, ceil, sqrt, exp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'siamese_fcn')\n",
    "sys.path.insert(1, 'datasets')\n",
    "sys.path.insert(1, 'util')\n",
    "from unet import Unet\n",
    "from siamunet_conc import SiamUnet_conc\n",
    "from siamunet_diff import SiamUnet_diff\n",
    "from fresunet import FresUNet\n",
    "from levir_dataset_loader import LEVIR_Dataset\n",
    "from preprocess_util import reshape_for_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9dc873",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0cf60ce-47a1-43c3-a478-37ba95274cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_MODIFIER = 10 # Tuning parameter, use 1 if unsure\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "PATCH_SIDE = 96\n",
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f4b8b45-d1fc-4218-afdd-6e906e2d6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LEVIR_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dirname, set_name, patch_side):\n",
    "        self.imgs_1 = {}\n",
    "        self.imgs_2 = {}\n",
    "        self.change_maps = {}\n",
    "        self.stride = 1\n",
    "        \n",
    "\n",
    "        self.n_patches_per_image = {}\n",
    "        self.n_patches = 0\n",
    "        self.patch_coords = []\n",
    "        self.patch_side = patch_side\n",
    "        n_pix = 0\n",
    "        true_pix = 0\n",
    "\n",
    "        for name in os.listdir(os.path.join(dirname,set_name, \"A\")):\n",
    "            img_name = set_name + \"-\" + name\n",
    "            a = reshape_for_torch(cv2.imread(os.path.join(dirname,set_name,\"A\", name)))\n",
    "            b = reshape_for_torch(cv2.imread(os.path.join(dirname,set_name, \"B\", name)))\n",
    "            label = reshape_for_torch(cv2.imread(os.path.join(dirname, set_name, \"label\", name)))\n",
    "\n",
    "            self.imgs_1[img_name] = a\n",
    "            self.imgs_2[img_name] = b\n",
    "            self.change_maps[img_name] = label\n",
    "\n",
    "            s = label.shape\n",
    "            n_pix += np.prod(s)\n",
    "            true_pix += label.sum()\n",
    "            \n",
    "            # calculate the number of patches\n",
    "            s = self.imgs_1[img_name].shape\n",
    "            n1 = ceil((s[1] - self.patch_side + 1) / self.stride)\n",
    "            n2 = ceil((s[2] - self.patch_side + 1) / self.stride)\n",
    "            n_patches_i = n1 * n2\n",
    "            self.n_patches_per_image[img_name] = n_patches_i\n",
    "            self.n_patches += n_patches_i\n",
    "\n",
    "            # generate path coordinates\n",
    "            for i in range(n1):\n",
    "                for j in range(n2):\n",
    "                    # coordinates in (x1, x2, y1, y2)\n",
    "                    current_patch_coords = (img_name, \n",
    "                                    [self.stride*i, self.stride*i + self.patch_side, self.stride*j, self.stride*j + self.patch_side],\n",
    "                                    [self.stride*(i + 1), self.stride*(j + 1)])\n",
    "            self.patch_coords.append(current_patch_coords)\n",
    "            self.weights = [ FP_MODIFIER * 2 * true_pix / n_pix, 2 * (n_pix - true_pix) / n_pix]\n",
    "\n",
    "    def get_img(self, im_name):\n",
    "        return self.imgs_1[im_name], self.imgs_2[im_name], self.change_maps[im_name]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_patches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_patch_coords = self.patch_coords[idx]\n",
    "        im_name = current_patch_coords[0]\n",
    "        limits = current_patch_coords[1]\n",
    "        centre = current_patch_coords[2]\n",
    "        \n",
    "        I1 = self.imgs_1[im_name][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        I2 = self.imgs_2[im_name][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        \n",
    "        label = self.change_maps[im_name][limits[0]:limits[1], limits[2]:limits[3]]\n",
    "        label = torch.from_numpy(1*np.array(label)).float()\n",
    "        \n",
    "        sample = {'I1': I1, 'I2': I2, 'label': label}\n",
    "        \n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5b24222-a11c-4a4f-8b60-92343c263a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([234.0378, -21.4038])\n"
     ]
    }
   ],
   "source": [
    "dirname = \"..\\\\data\\\\LEVIR-CD\"\n",
    "\n",
    "train_dataset = LEVIR_Dataset(dirname, \"train\", PATCH_SIDE)\n",
    "# weights = torch.FloatTensor(train_dataset.weights).cuda()\n",
    "weights = torch.FloatTensor(train_dataset.weights)\n",
    "print(weights)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
    "\n",
    "test_dataset = LEVIR_Dataset(dirname, \"test\", PATCH_SIDE)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
    "\n",
    "val_dataset = LEVIR_Dataset(dirname, \"val\", PATCH_SIDE)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a656e0",
   "metadata": {},
   "source": [
    "#### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1794e31-4389-47a1-a0fc-5863837da7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "import sys\n",
    "sys.path.insert(1, 'siamese_fcn')\n",
    "from unet import Unet\n",
    "from siamunet_conc import SiamUnet_conc\n",
    "from siamunet_diff import SiamUnet_diff\n",
    "from fresunet import FresUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d7bb4a7-5dca-4091-ab36-14c8dcdecb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-RGB | 1-RGBIr | 2-All bands s.t. resulution <= 20m | 3-All bands\n",
    "\n",
    "TYPE = 0\n",
    "\n",
    "\n",
    "if TYPE == 0:\n",
    "#     net, net_name = Unet(2*3, 2), 'FC-EF'\n",
    "#     net, net_name = SiamUnet_conc(3, 2), 'FC-Siam-conc'\n",
    "#     net, net_name = SiamUnet_diff(3, 2), 'FC-Siam-diff'\n",
    "    net, net_name = FresUNet(2*3, 2), 'FresUNet'\n",
    "elif TYPE == 1:\n",
    "#     net, net_name = Unet(2*4, 2), 'FC-EF'\n",
    "#     net, net_name = SiamUnet_conc(4, 2), 'FC-Siam-conc'\n",
    "#     net, net_name = SiamUnet_diff(4, 2), 'FC-Siam-diff'\n",
    "    net, net_name = FresUNet(2*4, 2), 'FresUNet'\n",
    "elif TYPE == 2:\n",
    "#     net, net_name = Unet(2*10, 2), 'FC-EF'\n",
    "#     net, net_name = SiamUnet_conc(10, 2), 'FC-Siam-conc'\n",
    "#     net, net_name = SiamUnet_diff(10, 2), 'FC-Siam-diff'\n",
    "    net, net_name = FresUNet(2*10, 2), 'FresUNet'\n",
    "elif TYPE == 3:\n",
    "#     net, net_name = Unet(2*13, 2), 'FC-EF'\n",
    "#     net, net_name = SiamUnet_conc(13, 2), 'FC-Siam-conc'\n",
    "#     net, net_name = SiamUnet_diff(13, 2), 'FC-Siam-diff'\n",
    "    net, net_name = FresUNet(2*13, 2), 'FresUNet'\n",
    "\n",
    "\n",
    "# net.cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(weight=weights) # to be used with logsoftmax output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f02db1ed-5abf-4f68-8476-3d30918ec307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 1103874\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Number of trainable parameters:', count_parameters(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02438a9d",
   "metadata": {},
   "source": [
    "#### Evaluate Models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e599c2a3-7e91-4ab0-ab22-b28780ce2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('net-best_epoch-1_fm-0.7394933126157746.pth.tar'))\n",
    "\n",
    "def train(n_epochs = N_EPOCHS, save = True):\n",
    "    t = np.linspace(1, n_epochs, n_epochs)\n",
    "    \n",
    "    epoch_train_loss = 0 * t\n",
    "    epoch_train_accuracy = 0 * t\n",
    "    epoch_train_change_accuracy = 0 * t\n",
    "    epoch_train_nochange_accuracy = 0 * t\n",
    "    epoch_train_precision = 0 * t\n",
    "    epoch_train_recall = 0 * t\n",
    "    epoch_train_Fmeasure = 0 * t\n",
    "    epoch_test_loss = 0 * t\n",
    "    epoch_test_accuracy = 0 * t\n",
    "    epoch_test_change_accuracy = 0 * t\n",
    "    epoch_test_nochange_accuracy = 0 * t\n",
    "    epoch_test_precision = 0 * t\n",
    "    epoch_test_recall = 0 * t\n",
    "    epoch_test_Fmeasure = 0 * t\n",
    "    \n",
    "#     mean_acc = 0\n",
    "#     best_mean_acc = 0\n",
    "    fm = 0\n",
    "    best_fm = 0\n",
    "    \n",
    "    lss = 1000\n",
    "    best_lss = 1000\n",
    "    \n",
    "    plt.figure(num=1)\n",
    "    plt.figure(num=2)\n",
    "    plt.figure(num=3)\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), weight_decay=1e-4)\n",
    "        \n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95)\n",
    "    \n",
    "    \n",
    "    for epoch_index in tqdm(range(n_epochs)):\n",
    "        net.train()\n",
    "        print('Epoch: ' + str(epoch_index + 1) + ' of ' + str(N_EPOCHS))\n",
    "\n",
    "        tot_count = 0\n",
    "        tot_loss = 0\n",
    "        tot_accurate = 0\n",
    "        class_correct = list(0. for i in range(2))\n",
    "        class_total = list(0. for i in range(2))\n",
    "#         for batch_index, batch in enumerate(tqdm(data_loader)):\n",
    "        for batch in train_loader:\n",
    "            I1 = Variable(batch['I1'].float().cuda())\n",
    "            I2 = Variable(batch['I2'].float().cuda())\n",
    "            label = torch.squeeze(Variable(batch['label'].cuda()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = net(I1, I2)\n",
    "            loss = criterion(output, label.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "        epoch_train_loss[epoch_index], epoch_train_accuracy[epoch_index], cl_acc, pr_rec = test(train_dataset)\n",
    "        epoch_train_nochange_accuracy[epoch_index] = cl_acc[0]\n",
    "        epoch_train_change_accuracy[epoch_index] = cl_acc[1]\n",
    "        epoch_train_precision[epoch_index] = pr_rec[0]\n",
    "        epoch_train_recall[epoch_index] = pr_rec[1]\n",
    "        epoch_train_Fmeasure[epoch_index] = pr_rec[2]\n",
    "        \n",
    "#         epoch_test_loss[epoch_index], epoch_test_accuracy[epoch_index], cl_acc, pr_rec = test(test_dataset)\n",
    "        epoch_test_loss[epoch_index], epoch_test_accuracy[epoch_index], cl_acc, pr_rec = test(test_dataset)\n",
    "        epoch_test_nochange_accuracy[epoch_index] = cl_acc[0]\n",
    "        epoch_test_change_accuracy[epoch_index] = cl_acc[1]\n",
    "        epoch_test_precision[epoch_index] = pr_rec[0]\n",
    "        epoch_test_recall[epoch_index] = pr_rec[1]\n",
    "        epoch_test_Fmeasure[epoch_index] = pr_rec[2]\n",
    "\n",
    "        plt.figure(num=1)\n",
    "        plt.clf()\n",
    "        l1_1, = plt.plot(t[:epoch_index + 1], epoch_train_loss[:epoch_index + 1], label='Train loss')\n",
    "        l1_2, = plt.plot(t[:epoch_index + 1], epoch_test_loss[:epoch_index + 1], label='Test loss')\n",
    "        plt.legend(handles=[l1_1, l1_2])\n",
    "        plt.grid()\n",
    "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
    "        plt.gcf().gca().set_xlim(left = 0)\n",
    "        plt.title('Loss')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.figure(num=2)\n",
    "        plt.clf()\n",
    "        l2_1, = plt.plot(t[:epoch_index + 1], epoch_train_accuracy[:epoch_index + 1], label='Train accuracy')\n",
    "        l2_2, = plt.plot(t[:epoch_index + 1], epoch_test_accuracy[:epoch_index + 1], label='Test accuracy')\n",
    "        plt.legend(handles=[l2_1, l2_2])\n",
    "        plt.grid()\n",
    "        plt.gcf().gca().set_ylim(0, 100)\n",
    "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
    "#         plt.gcf().gca().set_xlim(left = 0)\n",
    "        plt.title('Accuracy')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.figure(num=3)\n",
    "        plt.clf()\n",
    "        l3_1, = plt.plot(t[:epoch_index + 1], epoch_train_nochange_accuracy[:epoch_index + 1], label='Train accuracy: no change')\n",
    "        l3_2, = plt.plot(t[:epoch_index + 1], epoch_train_change_accuracy[:epoch_index + 1], label='Train accuracy: change')\n",
    "        l3_3, = plt.plot(t[:epoch_index + 1], epoch_test_nochange_accuracy[:epoch_index + 1], label='Test accuracy: no change')\n",
    "        l3_4, = plt.plot(t[:epoch_index + 1], epoch_test_change_accuracy[:epoch_index + 1], label='Test accuracy: change')\n",
    "        plt.legend(handles=[l3_1, l3_2, l3_3, l3_4])\n",
    "        plt.grid()\n",
    "        plt.gcf().gca().set_ylim(0, 100)\n",
    "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
    "#         plt.gcf().gca().set_xlim(left = 0)\n",
    "        plt.title('Accuracy per class')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.figure(num=4)\n",
    "        plt.clf()\n",
    "        l4_1, = plt.plot(t[:epoch_index + 1], epoch_train_precision[:epoch_index + 1], label='Train precision')\n",
    "        l4_2, = plt.plot(t[:epoch_index + 1], epoch_train_recall[:epoch_index + 1], label='Train recall')\n",
    "        l4_3, = plt.plot(t[:epoch_index + 1], epoch_train_Fmeasure[:epoch_index + 1], label='Train Dice/F1')\n",
    "        l4_4, = plt.plot(t[:epoch_index + 1], epoch_test_precision[:epoch_index + 1], label='Test precision')\n",
    "        l4_5, = plt.plot(t[:epoch_index + 1], epoch_test_recall[:epoch_index + 1], label='Test recall')\n",
    "        l4_6, = plt.plot(t[:epoch_index + 1], epoch_test_Fmeasure[:epoch_index + 1], label='Test Dice/F1')\n",
    "        plt.legend(handles=[l4_1, l4_2, l4_3, l4_4, l4_5, l4_6])\n",
    "        plt.grid()\n",
    "        plt.gcf().gca().set_ylim(0, 1)\n",
    "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
    "#         plt.gcf().gca().set_xlim(left = 0)\n",
    "        plt.title('Precision, Recall and F-measure')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        \n",
    "        \n",
    "#         mean_acc = (epoch_test_nochange_accuracy[epoch_index] + epoch_test_change_accuracy[epoch_index])/2\n",
    "#         if mean_acc > best_mean_acc:\n",
    "#             best_mean_acc = mean_acc\n",
    "#             save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_acc-' + str(mean_acc) + '.pth.tar'\n",
    "#             torch.save(net.state_dict(), save_str)\n",
    "        \n",
    "        \n",
    "#         fm = pr_rec[2]\n",
    "        fm = epoch_train_Fmeasure[epoch_index]\n",
    "        if fm > best_fm:\n",
    "            best_fm = fm\n",
    "            save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_fm-' + str(fm) + '.pth.tar'\n",
    "            torch.save(net.state_dict(), save_str)\n",
    "        \n",
    "        lss = epoch_train_loss[epoch_index]\n",
    "        if lss < best_lss:\n",
    "            best_lss = lss\n",
    "            save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_loss-' + str(lss) + '.pth.tar'\n",
    "            torch.save(net.state_dict(), save_str)\n",
    "            \n",
    "            \n",
    "#         print('Epoch loss: ' + str(tot_loss/tot_count))\n",
    "        if save:\n",
    "            im_format = 'png'\n",
    "    #         im_format = 'eps'\n",
    "\n",
    "            plt.figure(num=1)\n",
    "            plt.savefig(net_name + '-01-loss.' + im_format)\n",
    "\n",
    "            plt.figure(num=2)\n",
    "            plt.savefig(net_name + '-02-accuracy.' + im_format)\n",
    "\n",
    "            plt.figure(num=3)\n",
    "            plt.savefig(net_name + '-03-accuracy-per-class.' + im_format)\n",
    "\n",
    "            plt.figure(num=4)\n",
    "            plt.savefig(net_name + '-04-prec-rec-fmeas.' + im_format)\n",
    "        \n",
    "    out = {'train_loss': epoch_train_loss[-1],\n",
    "           'train_accuracy': epoch_train_accuracy[-1],\n",
    "           'train_nochange_accuracy': epoch_train_nochange_accuracy[-1],\n",
    "           'train_change_accuracy': epoch_train_change_accuracy[-1],\n",
    "           'test_loss': epoch_test_loss[-1],\n",
    "           'test_accuracy': epoch_test_accuracy[-1],\n",
    "           'test_nochange_accuracy': epoch_test_nochange_accuracy[-1],\n",
    "           'test_change_accuracy': epoch_test_change_accuracy[-1]}\n",
    "    \n",
    "    print('pr_c, rec_c, f_meas, pr_nc, rec_nc')\n",
    "    print(pr_rec)\n",
    "    \n",
    "    return out\n",
    "\n",
    "L = 1024\n",
    "N = 2\n",
    "\n",
    "def test(dset):\n",
    "    net.eval()\n",
    "    tot_loss = 0\n",
    "    tot_count = 0\n",
    "    tot_accurate = 0\n",
    "    \n",
    "    n = 2\n",
    "    class_correct = list(0. for i in range(n))\n",
    "    class_total = list(0. for i in range(n))\n",
    "    class_accuracy = list(0. for i in range(n))\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for img_index in dset.names:\n",
    "        I1_full, I2_full, cm_full = dset.get_img(img_index)\n",
    "        \n",
    "        s = cm_full.shape\n",
    "        \n",
    "\n",
    "        steps0 = np.arange(0,s[0],ceil(s[0]/N))\n",
    "        steps1 = np.arange(0,s[1],ceil(s[1]/N))\n",
    "        for ii in range(N):\n",
    "            for jj in range(N):\n",
    "                xmin = steps0[ii]\n",
    "                if ii == N-1:\n",
    "                    xmax = s[0]\n",
    "                else:\n",
    "                    xmax = steps0[ii+1]\n",
    "                ymin = jj\n",
    "                if jj == N-1:\n",
    "                    ymax = s[1]\n",
    "                else:\n",
    "                    ymax = steps1[jj+1]\n",
    "                I1 = I1_full[:, xmin:xmax, ymin:ymax]\n",
    "                I2 = I2_full[:, xmin:xmax, ymin:ymax]\n",
    "                cm = cm_full[xmin:xmax, ymin:ymax]\n",
    "\n",
    "                I1 = Variable(torch.unsqueeze(I1, 0).float()).cuda()\n",
    "                I2 = Variable(torch.unsqueeze(I2, 0).float()).cuda()\n",
    "                cm = Variable(torch.unsqueeze(torch.from_numpy(1.0*cm),0).float()).cuda()\n",
    "\n",
    "\n",
    "                output = net(I1, I2)\n",
    "                loss = criterion(output, cm.long())\n",
    "        #         print(loss)\n",
    "                tot_loss += loss.data * np.prod(cm.size())\n",
    "                tot_count += np.prod(cm.size())\n",
    "\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "                c = (predicted.int() == cm.data.int())\n",
    "                for i in range(c.size(1)):\n",
    "                    for j in range(c.size(2)):\n",
    "                        l = int(cm.data[0, i, j])\n",
    "                        class_correct[l] += c[0, i, j]\n",
    "                        class_total[l] += 1\n",
    "                        \n",
    "                pr = (predicted.int() > 0).cpu().numpy()\n",
    "                gt = (cm.data.int() > 0).cpu().numpy()\n",
    "                \n",
    "                tp += np.logical_and(pr, gt).sum()\n",
    "                tn += np.logical_and(np.logical_not(pr), np.logical_not(gt)).sum()\n",
    "                fp += np.logical_and(pr, np.logical_not(gt)).sum()\n",
    "                fn += np.logical_and(np.logical_not(pr), gt).sum()\n",
    "        \n",
    "    net_loss = tot_loss/tot_count\n",
    "    net_accuracy = 100 * (tp + tn)/tot_count\n",
    "    \n",
    "    for i in range(n):\n",
    "        class_accuracy[i] = 100 * class_correct[i] / max(class_total[i],0.00001)\n",
    "\n",
    "    prec = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "    f_meas = 2 * prec * rec / (prec + rec)\n",
    "    prec_nc = tn / (tn + fn)\n",
    "    rec_nc = tn / (tn + fp)\n",
    "    \n",
    "    pr_rec = [prec, rec, f_meas, prec_nc, rec_nc]\n",
    "        \n",
    "    return net_loss, net_accuracy, class_accuracy, pr_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b38b9-c975-41d6-b39e-6d6ddf533ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 of 50\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t_start = time.time()\n",
    "out_dic = train()\n",
    "t_end = time.time()\n",
    "print(out_dic)\n",
    "print('Elapsed time:')\n",
    "print(t_end - t_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
